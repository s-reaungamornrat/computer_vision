{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fd1d25b-dd90-40f5-91b4-9a41144dbbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "__import__(\"os\").environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "260287c4-511b-436e-b381-8bb9bcaeea7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "seed=0\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce9d6af7-d8be-47e7-9ebe-44449790c9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../..')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from computer_vision.yolov11.modules.detector import DetectionModel\n",
    "from computer_vision.yolov11.parameter_parser import parser\n",
    "from computer_vision.yolov11.utils.check import check_imgsz\n",
    "from computer_vision.yolov11.data.dataset import YOLODataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b94cb24e-ee13-4ea9-8910-8afc04acfe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dirpath=r'D:/data/ultralytics/coco128'\n",
    "result_dirpath='D:/results/yolov11/training'\n",
    "\n",
    "argument=f'''--root {data_dirpath} --image-dirname images/train2017 --label-dirname labels/train2017\n",
    "--data-cfg ../coco128.yaml --hyperparam ../default.yaml --model-cfg ../yolo11.yaml \n",
    "--batch-size 2 --checkpoint-dirpath {result_dirpath}/checkpoints '''\n",
    "args=parser.parse_args(argument.split())\n",
    "\n",
    "if not os.path.isdir(args.checkpoint_dirpath): os.makedirs(args.checkpoint_dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd6706aa-fca1-4ad8-b32e-b5d30ee9154d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In BaseModel._predict_once max_idx -1 embed {-1}\n",
      "stride  tensor([ 8., 16., 32.])\n",
      "grid size  32  args.imgsz  640\n",
      "args.imgsz  640\n"
     ]
    }
   ],
   "source": [
    "device=torch.device('cpu') if not torch.cuda.is_available() else torch.device('cuda')\n",
    "\n",
    "model=DetectionModel(cfg=args.model_cfg, ch=3)\n",
    "print('stride ', model.stride)\n",
    "gs = max(int(model.stride.max() if hasattr(model, \"stride\") else 32), 32)  # grid size (max stride)\n",
    "print('grid size ', gs, ' args.imgsz ', args.imgsz)\n",
    "args.imgsz=check_imgsz(args.imgsz, stride=gs, floor=gs, max_dim=1)  \n",
    "print('args.imgsz ', args.imgsz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d311b93-ccf9-4396-8652-bbe2bfcea5d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8., 16., 32.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e29897bc-faf6-48e7-8b1b-6ee173efdc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In data.dataset.YOLODataset.update_images_labels cache path D:\\data\\ultralytics\\coco128\\labels\\train2017.cache exist. Load it!!!\n",
      "Scanning D:\\data\\ultralytics\\coco128\\labels\\train2017.cache ... 126 images with 2 missing and 0 empty files as well as 0 corrupt files\n",
      "max_buffer_length  16  ni  128\n",
      "In data.dataset.YOLODataset.update_images_labels cache path D:\\data\\ultralytics\\coco128\\labels\\train2017.cache exist. Load it!!!\n",
      "Scanning D:\\data\\ultralytics\\coco128\\labels\\train2017.cache ... 126 images with 2 missing and 0 empty files as well as 0 corrupt files\n",
      "max_buffer_length  0  ni  128\n",
      "len(train_dataset.im_files)  128  len(train_dataset)  128  len(train_loader)  64\n"
     ]
    }
   ],
   "source": [
    "train_dataset=YOLODataset(img_path=os.path.join(args.root, args.image_dirname),label_path=os.path.join(args.root, args.label_dirname),\n",
    "                    data=args.data_cfg, hyp=args.hyperparam, imgsz=args.imgsz, cache=True, augment=True, rect=False, batch_size=args.batch_size, \n",
    "                    stride=gs, pad=0.5,  single_cls=False, classes=None, fraction=1., channels=3)\n",
    "val_dataset=YOLODataset(img_path=os.path.join(args.root, args.image_dirname),label_path=os.path.join(args.root, args.label_dirname),\n",
    "                    data=args.data_cfg, hyp=args.hyperparam, imgsz=args.imgsz, cache=True, augment=False, rect=False, batch_size=args.batch_size, \n",
    "                    stride=gs, pad=0.5,  single_cls=False, classes=None, fraction=1., channels=3)\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset, batch_size=args.batch_size, shuffle=False, sampler=None, batch_sampler=None, \n",
    "                                       num_workers=0, collate_fn=YOLODataset.collate_fn, pin_memory=False, drop_last=True, \n",
    "                                       timeout=0, worker_init_fn=None, prefetch_factor=None, persistent_workers=False)\n",
    "val_loader=torch.utils.data.DataLoader(dataset=val_dataset, batch_size=args.batch_size, shuffle=False, sampler=None, batch_sampler=None, \n",
    "                                       num_workers=0, collate_fn=YOLODataset.collate_fn, pin_memory=False, drop_last=True, \n",
    "                                       timeout=0, worker_init_fn=None, prefetch_factor=None, persistent_workers=False)\n",
    "print('len(train_dataset.im_files) ', len(train_dataset.im_files), ' len(train_dataset) ', len(train_dataset), ' len(train_loader) ', len(train_loader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345d35c5-18ad-4383-9476-7c4247b859e0",
   "metadata": {},
   "source": [
    "[`_setup_train`](https://github.com/ultralytics/ultralytics/blob/main/ultralytics/engine/trainer.py#L264)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "559652db-7852-47dd-aa3e-4e97506d8d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(os.path.join(args.checkpoint_dirpath, args.latest_checkpoint)):\n",
    "    checkpoint=torch.load(os.path.join(args.checkpoint_dirpath, args.latest_checkpoint), map_location=torch.device('cpu'), weights_only=True) # may have model. as added prefix\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "model.to(device)\n",
    "model.names=train_dataset.data[\"names\"]\n",
    "always_freeze_names=['.dfl'] # always freeze these layers\n",
    "for k, v in model.named_parameters():\n",
    "    if any(x in k for x in always_freeze_names):\n",
    "        print(f'Freeze {k}')\n",
    "        v.requires_grad=False\n",
    "    elif not v.requires_grad and v.dtype.is_floating_point: \n",
    "        # only floating point tensor can require gradients\n",
    "        v.requires_grad=True\n",
    "        print(f'Parameter {k} was originally frozen')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c764f1-ab63-4a85-9cfb-c65813672688",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:op_cv]",
   "language": "python",
   "name": "conda-env-op_cv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
