{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91cc0590-2dc2-4fb5-b4f6-13599ccce35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "__import__(\"os\").environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4356d02e-5903-4d89-a9da-0881dbbc40a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "seed=0\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "261612e2-0324-4902-95d5-3f78897f465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../..')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from computer_vision.yolov11.modules.detector import DetectionModel\n",
    "from computer_vision.yolov11.parameter_parser import parser\n",
    "from computer_vision.yolov11.utils.check import check_imgsz\n",
    "from computer_vision.yolov11.data.dataset import YOLODataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47041086-d344-425c-88e6-62c78f5ee90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dirpath=r'D:/data/ultralytics/coco128'\n",
    "result_dirpath='D:/results/yolov11/training'\n",
    "\n",
    "argument=f'''--root {data_dirpath} --train-image-dirname images/train2017 --train-label-dirname labels/train2017\n",
    "--val-image-dirname images/train2017 --val-label-dirname labels/train2017\n",
    "--data-cfg ../coco128.yaml --hyperparam ../default.yaml --model-cfg ../yolo11.yaml \n",
    "--batch-size 2 --output-dirpath {result_dirpath} --checkpoint-dirpath {result_dirpath}/checkpoints \n",
    "--save-period 1 '''\n",
    "args=parser.parse_args(argument.split())\n",
    "\n",
    "if not os.path.isdir(args.checkpoint_dirpath): os.makedirs(args.checkpoint_dirpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebfc4e86-8f46-4edb-a2da-999e62cbd773",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from typing import Any\n",
    "from pathlib import Path\n",
    "from argparse import Namespace\n",
    "\n",
    "import yaml\n",
    "\n",
    "from computer_vision.yolov11.utils.torch_utils import init_seeds\n",
    "\n",
    "class DetectionTrainer:\n",
    "\n",
    "    def __init__(self, args:Namespace, cfg:str | dict, inch:int=3):\n",
    "        \"\"\"\n",
    "        Initialize a DetectionTrainer object for training YOLO\n",
    "        Args:\n",
    "            args (Namespace): Training parameters\n",
    "            cfg (str | dict): Configuration dict containing training parameters\n",
    "            inch (int): The number of input channels\n",
    "        \"\"\"\n",
    "        if isinstance(cfg, str):\n",
    "            cfg=Path(cfg) # Hyperparameters\n",
    "            assert cfg.is_file(), f'{cfg} does not exist'\n",
    "            with open(cfg) as f: self.cfg=yaml.load(f, Loader=yaml.SafeLoader)\n",
    "        elif not isinstance(cfg, dict): raise TypeError(f'cfg must be dict/str but got {type(cfg)}')\n",
    "        else: self.cfg=cfg\n",
    "            \n",
    "        if isinstance(args.data_cfg, str):\n",
    "            data=Path(args.data_cfg)\n",
    "            assert data.is_file(), f'{data} does not exist'\n",
    "            with open(data, encoding=\"utf8\") as f: self.data=yaml.load(f, Loader=yaml.SafeLoader)\n",
    "\n",
    "        self.inch=inch \n",
    "        # Merge the namespace without overriding the original args\n",
    "        for k, v in vars(Namespace(**self.cfg)).items():\n",
    "            if not hasattr(args, k): setattr(args, k, v)\n",
    "        self.args=args\n",
    "        self.device=torch.device('cpu') if not torch.cuda.is_available() else torch.device('cuda')\n",
    "        \n",
    "        init_seeds(seed=self.args.seed, deterministic=self.args.deterministic)\n",
    "\n",
    "        # Directories\n",
    "        self.save_dir=Path(self.args.output_dirpath)\n",
    "        self.wdir=Path(self.args.checkpoint_dirpath) # weight directory\n",
    "        if not self.save_dir.is_dir(): os.makedirs(self.save_dir)\n",
    "        if not self.wdir.is_dir(): os.makedirs(self.wdir)\n",
    "        self.last, self.best=self.wdir/self.args.latest_checkpoint, self.wdir/self.args.best_checkpoint\n",
    "        self.save_period=self.args.save_period\n",
    "\n",
    "        self.batch_size=self.args.batch_size\n",
    "        # in case users accidentally pass epochs=None \n",
    "        self.epochs=self.args.epochs or 100 \n",
    "        self.start_epoch=0\n",
    "\n",
    "        # setting worker=0 yields faster CPU training as time dominated by inference, not dataloading\n",
    "        if self.device.type in {'cpu', 'mps'}: self.args.worker=0\n",
    "\n",
    "        # check data \n",
    "        self.args.root=Path(self.args.root)\n",
    "        for dirname in [args.train_image_dirname, args.train_label_dirname, args.val_image_dirname, args.val_label_dirname]:\n",
    "            assert (self.args.root/dirname).is_dir(), f'{Path(self.args.root)/dirname} does not exist'\n",
    "\n",
    "        self.ema=None\n",
    "\n",
    "        # Optimization utils init\n",
    "        self.lf=None\n",
    "        self.scheduler=None\n",
    "\n",
    "        # Epoch level metrics\n",
    "        self.best_fitness=None\n",
    "        self.fitness=None\n",
    "        self.loss=None\n",
    "        self.tloss=None\n",
    "        self.loss_names=[\"Loss\"]\n",
    "        self.cvs=self.save_dir/\"result.csv\"\n",
    "        self.plot_idx=[0,1,2]\n",
    "        self.world_size=0 # single GPU training\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e91a2083-7d13-4388-bece-403b0ccc78a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer=DetectionTrainer(args, cfg=args.hyperparam, inch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa01f84-2626-4c3b-ba3a-2c8c3d39bad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _do_train(self)\n",
    "#    self._setup_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33c46aaf-c03a-4e5a-9257-8a2486108922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In BaseModel._predict_once max_idx -1 embed {-1}\n",
      "Freezing layer model.23.dfl.conv.weight\n",
      "gs  32  trainer.args.imgsz  640\n"
     ]
    }
   ],
   "source": [
    "# def _setup_train(self):\n",
    "\n",
    "trainer.model=DetectionModel(cfg=trainer.args.model_cfg, ch=trainer.inch)\n",
    "trainer.model.names=trainer.data[\"names\"]\n",
    "\n",
    "always_freeze_names=['.dfl'] # always freeze these layers\n",
    "for k, v in trainer.model.named_parameters():\n",
    "    if any(x in k for x in always_freeze_names):\n",
    "        print(f'Freezing layer {k}')\n",
    "        v.requires_grad=False\n",
    "    elif not v.requires_grad and v.dtype.is_floating_point: \n",
    "        # only floating point can require gradients\n",
    "        print(f'Unfreeze layer {k}')\n",
    "        v.requires_grad=True\n",
    "\n",
    "# Check imgsz\n",
    "gs=max( (int(trainer.model.stride.max()) if hasattr(trainer.model, 'stride') else 32), 32 ) # grid size / max stride\n",
    "trainer.args.imgsz=check_imgsz(trainer.args.imgsz, stride=gs, floor=gs, max_dim=1) \n",
    "print('gs ', gs, ' trainer.args.imgsz ', trainer.args.imgsz)\n",
    "trainer.stride=gs # for multiscale training\n",
    "\n",
    "# Dataloaders\n",
    "train_dataset=YOLODataset(img_path=(trainer.args.root/trainer.args.train_image_dirname),\n",
    "                          label_path=(trainer.args.root/trainer.args.train_label_dirname),\n",
    "                          data=trainer.data, hyp=trainer.cfg, imgsz=trainer.args.imgsz, cache=True, augment=True, rect=False,\n",
    "                          batch_size=trainer.args.batch_size, stride=gs, pad=0.5,  single_cls=False, classes=None, fraction=1.,\n",
    "                          channels=trainer.inch)\n",
    "val_dataset=YOLODataset(img_path=(trainer.args.root/trainer.args.val_image_dirname),\n",
    "                        label_path=(trainer.args.root/trainer.args.val_label_dirname),\n",
    "                        data=trainer.data, hyp=trainer.cfg, imgsz=trainer.args.imgsz, cache=True, augment=False, rect=False, \n",
    "                        batch_size=trainer.args.batch_size, stride=gs, pad=0.5,  single_cls=False, classes=None, fraction=1., channels=trainer.inch)\n",
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset, batch_size=trainer.args.batch_size, shuffle=False, sampler=None, batch_sampler=None, \n",
    "                                       num_workers=trainer.args.worker, collate_fn=YOLODataset.collate_fn, pin_memory=False, drop_last=True, \n",
    "                                       timeout=0, worker_init_fn=None, prefetch_factor=None, persistent_workers=False)\n",
    "val_loader=torch.utils.data.DataLoader(dataset=val_dataset, batch_size=args.batch_size, shuffle=False, sampler=None, batch_sampler=None, \n",
    "                                       num_workers=trainer.args.worker, collate_fn=YOLODataset.collate_fn, pin_memory=False, drop_last=False, \n",
    "                                       timeout=0, worker_init_fn=None, prefetch_factor=None, persistent_workers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47781c3a-83e5-4918-9735-3ccc349a5ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf07a75-4a4b-44a5-bd2d-0a6cdebbdec5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "op_cv",
   "language": "python",
   "name": "op_cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
